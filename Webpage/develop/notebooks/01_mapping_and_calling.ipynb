{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e39a7f3-7b5d-43db-ab17-6e1f1aa741a1",
   "metadata": {},
   "source": [
    "# Mapping and SNP Calling Tutorial\n",
    "\n",
    "High-throughput sequencing technologies have in the past few years been producing millions of reads of human genome and other species. To be useful, this genetic information has to be 'put together' in a smart way, in the same way as the pieces of a puzzle (reads) need to be mounted according to a picture (reference genome). \n",
    "\n",
    "The present tutorial, like the rest of the course material, is available at our [open-source github repository](https://github.com/hds-sandbox/Popgen_course_aarhus), and is based on [Kasper Munk's course repository](https://github.com/kaspermunch/PopulationGenomicsCourse).\n",
    "\n",
    "## Content\n",
    "\n",
    "In this exercise section you will be exposed to different softwares used for mapping reads to a reference sequence and calling variants from the produced alignments. We will use a dataset composed of 28 individuals from 3 different regions: Africa, EastAsia and WestEurasia. You can find the metadata file, containing sample IDs and some extra information for each sample here: `../../Data/metadata/Sample_meta_subset.tsv`\n",
    "\n",
    "![](img/unnamed-chunk-1-1.png)\n",
    "\n",
    "This dataset is a subset of the [Simons Diversity Project](https://www.nature.com/articles/nature18964).\n",
    "The following tutorial is based on the individual **S_Ju_hoan_North-3**, which is an african sample from Namibia.\n",
    "\n",
    "## How to make this notebook work\n",
    "\n",
    "* In this notebook we will use primarily `R` and `command line bash` commands.\n",
    "* This notebook integrates multiple coding languages. This means you need to choose a kernel every time we shift from one language to another. A kernel contains a programming language and the necessary packages to run the course material. To choose a kernel, go on the menu on the top of the page and select `Kernel --> Change Kernel`, and then select the preferred one. We will shift between two kernels, and along the code in this notebook you will see a picture telling you to change kernel. The two pictures are below:\n",
    "\n",
    "<img src=\"img/bash.png\" alt=\"Bash\" width=\"80\"> Shift to the `Bash` kernel\n",
    "\n",
    "<img src=\"img/R.png\" alt=\"R\" width=\"80\"> Shift to the `popgen course` kernel\n",
    "* You can run the code in each cell by clicking on the run cell sign in the toolbar, or simply by pressing <kbd>Shift</kbd>+<kbd>Enter</kbd>. When the code is done running, a small green check sign will appear on the left side.\n",
    "* You need to run the cells in sequential order to execute the analysis. Please do not run a cell until the one above is done running, and do not skip any cells\n",
    "* The code goes along with textual descriptions to help you understand what happens. Please try not to focus on understanding the code itself in too much detail - but rather try to focus on the explanations and on the output of the commands \n",
    "*   You can create new code cells by pressing `+` in the Menu bar above or by pressing <kbd>B</kbd> after you select a cell. \n",
    "\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "At the end of this tutorial you will be able to\n",
    "\n",
    "- **handle and understand** the various steps needed to prepare data for alignment using standard tools like `samtools`\n",
    "- **apply** genome alignment tools (`burrows-wheeler aligner BWA` and `Minimap2`) and **comment** their outcome\n",
    "- **make sense** of the various data formats (`fasta`, `fastq`, `sam/bam`, `vcf`, ...) \n",
    "- **explore and analyze** data on a genome viewer\n",
    "\n",
    "## Mapping reads against the reference\n",
    "\n",
    "The first step when dealing with raw reads is mapping (aligning) them to a reference sequence. We will use two different aligners for mapping the reads against the reference genome; one is the classical Burrows-Wheeler aligner (BWA), and the other is the newer and faster Minimap2. Minimap2 is especially faster (up to 50X faster) and as accurate as BWA in aligning long reads, but works also well with short read data like ours.\n",
    "\n",
    "Two input files are needed to do genome mapping:\n",
    "\n",
    "- Fasta file containing your reference genome Which was downloaded from [hg19](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/chromosomes/chr2.fa.gz). We need to copy the file from our `Data` folder, since it is a protected folder where we cannot write any file.\n",
    "- The reads in fastq format, which can be found in `Data/fastq/`. Here we will not need to copy the files to another folder, because we will only read them.\n",
    "\n",
    "We create a link to `Data`, so it is easier to access it. Then we make a folder called `Reference` and copy the file `chr2.fa` in it. Finally we create a folder where to save our results.\n",
    "\n",
    "<img src=\"img/bash.png\" alt=\"Bash\" width=\"80\"> Choose the `Bash` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68829ed0-a541-4eaa-b8d8-74d24dced0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mkdir -p ../../Reference\n",
    "cp ../../Data/fasta/chr2.fa ../../Reference/\n",
    "ln -s ../../Data\n",
    "ln -s ../../Reference\n",
    "mkdir -p Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be5f4e-f217-4bf9-b428-dc69dbd18363",
   "metadata": {},
   "source": [
    "### Alignment with BWA\n",
    "\n",
    "BWA allows for fast and accurate alignment of short reads to an indexed reference sequence. [Here](http://bio-bwa.sourceforge.net/bwa.shtml) is the manual. We will focus on a 10 MB region of chromosome 2 (from 135MB to 145MB), which contains the [lactase gene](https://www.genecards.org/cgi-bin/carddisp.pl?gene=LCT).\n",
    "\n",
    "First we need to index the reference file for later use. This creates index files used to perform the alignment. To produce these files, run the following command. Here, `-a bwtsw` specifies the indexing algorithm; specifically `bwtsw` which is capable of handling large genomes such as the human genome (the standard option is `-a is`, which cannot handle beyond 2MB genomes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9320e79-b360-4f78-9f17-925f32e747b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 1.54 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[BWTIncCreate] textLength=486398746, availableWord=46224508\n",
      "[BWTIncConstructFromPacked] 10 iterations done. 75165770 characters processed.\n",
      "[BWTIncConstructFromPacked] 20 iterations done. 139904490 characters processed.\n",
      "[BWTIncConstructFromPacked] 30 iterations done. 197440426 characters processed.\n",
      "[BWTIncConstructFromPacked] 40 iterations done. 248574506 characters processed.\n",
      "[BWTIncConstructFromPacked] 50 iterations done. 294018586 characters processed.\n",
      "[BWTIncConstructFromPacked] 60 iterations done. 334405370 characters processed.\n",
      "[BWTIncConstructFromPacked] 70 iterations done. 370297226 characters processed.\n",
      "[BWTIncConstructFromPacked] 80 iterations done. 402193962 characters processed.\n",
      "[BWTIncConstructFromPacked] 90 iterations done. 430539834 characters processed.\n",
      "[BWTIncConstructFromPacked] 100 iterations done. 455729658 characters processed.\n",
      "[BWTIncConstructFromPacked] 110 iterations done. 478114410 characters processed.\n",
      "[bwt_gen] Finished constructing BWT in 115 iterations.\n",
      "[bwa_index] 120.03 seconds elapse.\n",
      "[bwa_index] Update BWT... 1.17 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.99 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 56.32 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index -a bwtsw Reference/chr2.fa\n",
      "[main] Real time: 182.078 sec; CPU: 180.045 sec\n"
     ]
    }
   ],
   "source": [
    "bwa index -a bwtsw Reference/chr2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7503e70-51c9-43d2-b63f-996fefa6a222",
   "metadata": {},
   "source": [
    "The resulting `bwa` index files are in the same folder `Reference` as the reference genome file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61775402-45a5-440c-a45c-34f695a4216e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2.fa  chr2.fa.amb  chr2.fa.ann  chr2.fa.bwt  chr2.fa.pac  chr2.fa.sa\n"
     ]
    }
   ],
   "source": [
    "ls Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb579a-6706-4eed-9b5a-13fcc4139f14",
   "metadata": {},
   "source": [
    "\n",
    "We also need to generate a fasta file index, which contains the genomic coordinates of the reference file. This can be done using the `samtools` program `faidx`. Again, the resulting index files are in the `Reference` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d39e37-4832-4a3a-9fa5-1b5be484e8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools faidx Reference/chr2.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e49451-2cc0-41b4-8754-6160f2f18aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2.fa      chr2.fa.ann  chr2.fa.fai  chr2.fa.sa\n",
      "chr2.fa.amb  chr2.fa.bwt  chr2.fa.pac\n"
     ]
    }
   ],
   "source": [
    "ls Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86ff6a-921f-4baa-b66a-bb8b9a870cf2",
   "metadata": {},
   "source": [
    "Now you can map the reads to the reference. This will take a few minutes. Note how the alignment command `bwa mem` is piped with the symbol `|` at the end of the command. This allows the output of the alignment with `bwa mem` not to be written anywhere, but to be transferred (piped) directly into the following command `samtools sort`, which sorts the aligned genome by coordinates and creates a file in `bam` format. The sorting is necessary as the output of `bwa mem` is unsorted, and sorted files are usually the standard for genomic analysis. The piping speeds up the running time of the commands, avoiding to write intermediate files, and thus saving also disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f16461-5505-4562-af09-58df35d1dce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1600642 sequences (160000012 bp)...\n",
      "[M::process] 1586946 single-end sequences; 13696 paired-end sequences\n",
      "[M::process] read 1600786 sequences (160000003 bp)...\n",
      "[M::mem_process_seqs] Processed 1586946 reads in 206.812 CPU sec, 14.668 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 710, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (74, 86, 95)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (32, 137)\n",
      "[M::mem_pestat] mean and std.dev: (82.89, 15.62)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (11, 158)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 13696 reads in 2.811 CPU sec, 0.193 real sec\n",
      "[M::process] 1588148 single-end sequences; 12638 paired-end sequences\n",
      "[M::process] read 642285 sequences (64201734 bp)...\n",
      "[M::mem_process_seqs] Processed 1588148 reads in 183.861 CPU sec, 13.272 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 757, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (73, 85, 95)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (29, 139)\n",
      "[M::mem_pestat] mean and std.dev: (81.95, 16.02)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (7, 161)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 12638 reads in 2.390 CPU sec, 0.162 real sec\n",
      "[M::process] 637205 single-end sequences; 5080 paired-end sequences\n",
      "[M::mem_process_seqs] Processed 637205 reads in 78.603 CPU sec, 6.054 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 300, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (74, 86, 94)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (34, 134)\n",
      "[M::mem_pestat] mean and std.dev: (82.85, 14.79)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (14, 154)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 5080 reads in 1.033 CPU sec, 0.072 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -t 16 -p Reference/chr2.fa ./Data/fastq/S_Ju_hoan_North-3.region.fq\n",
      "[main] Real time: 48.797 sec; CPU: 478.664 sec\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n"
     ]
    }
   ],
   "source": [
    "bwa mem -t 16 -p Reference/chr2.fa './Data/fastq/S_Ju_hoan_North-3.region.fq' | samtools sort -O BAM -o './Results/S_Ju_hoan_North-3.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07590a13-9da2-4498-b811-9960a49b00cc",
   "metadata": {},
   "source": [
    "Bam files follow this structure, where each element is tab-separated inside the output file:\n",
    "\n",
    "![Alt text](https://us.v-cdn.net/5019796/uploads/editor/f4/uuzmf2cbau1y.png)\n",
    "\n",
    "- Read name: ID for the given read.\n",
    "- Flags: Combination of bitwise FLAGs that provide information on how the read is mapped  [Extra information](https://broadinstitute.github.io/picard/explain-flags.html).\n",
    "- Position: Chromosome and position of the first base in the alignment. \n",
    "- MAPQ: Probability of wrong mapping of the read. It's in Phred scale, so higher numbers mean lower probabilities:\n",
    "![Alt_text](https://genome.sph.umich.edu/w/images/math/e/9/d/e9dc88d1834c4579de12153a67ac3afa.png)\n",
    "- CIGAR: summary of the alignment, including start position on the reference sequence, matches, mismatches, deletions and insertions. It may also include information on soft/hard clipping, i.e bases in the 3' and 5' ends of teh read that are not part of the alignment.\n",
    "[Extra information](https://wiki.bits.vib.be/index.php/CIGAR)\n",
    "- Mate information: chromosome and start position of teh read pair, and inferred insert size.\n",
    "- Quality scores: base qualities of the read.\n",
    "- Metadata: optional extra information. \n",
    "\n",
    "For more information, read [this](https://samtools.github.io/hts-specs/SAMv1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791666ad-5e7f-4c2a-b668-dd06d1f4b06e",
   "metadata": {},
   "source": [
    "Have a look at the bam file generated and compare it with the structure above. There is an error message, but do not mind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961004dc-2120-4965-8170-37429a90599a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS2000-690_130:3:2115:19816:65272\t16\t2\t48688\t0\t100M\t*\t0\t0\tTCATGTTCTTTGCAGAGACACGAATGGAGCTGGAATCCATTATCTTCAGCAAACTAACACAGGAACAGAAAACCAAACACTGCATGTTCTCACTCATAAG\tCCDDCCEAEEFFFFFFHGHHGJJJIJJIJJJJJJGJJIGJJJJJIJJIJJIIGIJJIGHJJJJJJJJIJJIHJIIIHGDJIJIHFIIHHHHFFFFFFCCC\tNM:i:8\tMD:Z:6A8G4T1G12G44C0A12T5\tAS:i:60\tXS:i:59\n",
      "HS2000-690_130:4:2202:2325:9318\t16\t2\t126500\t0\t100M\t*\t0\t0\tCTCAGTGCTCAATGGTGCCCAGGCTGGAGTGCAGTGGCGTGATCTCGGCTCGCTACAACCTCCACCTCCCAGCCGCCTGCCTTGGCCTCCCAAAGTGCCG\tDCCA83DDCDDC?B<<8DBAABCC>9DCC@CA@BB?<BCAA?55??;/@?@;;>BC?5B;(A=-HGDGGF@7BHGGDGGHGGEC@GJHHHHHFFFDD@@@\tNM:i:0\tMD:Z:100\tAS:i:100\tXS:i:100\n",
      "HS2000-690_130:2:1311:9371:14324\t0\t2\t127285\t0\t100M\t*\t0\t0\tGAAAAATTCTTCTGCCTTGGGATCCTGTTGATCTATGACCTTACCCCCAACCCTGTGCTCTCTGAAACATGTGCTGTGTCCACTCAGGGTTAAATGGATT\t@@CFFFFFGHHHHJJJGJIFHIIJJJIIJGEGIJGFHFIGIIJIIIIJJJIJJJJJGCGIIJJJ;@EHG>E?EEC?@CBBDFEEEDAABCA2>(,5>:AC\tNM:i:0\tMD:Z:100\tAS:i:100\tXS:i:100\n",
      "HS2000-690_130:3:2307:1163:23064\t0\t2\t130911\t0\t41M59S\t*\t0\t0\tTCTTCTTGCTCTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTGGGGGGAGTTGTTAAAGTTTTTTCTCATCCCTTTTAAAATTTTTTTAAAATTTTTA\tCCCFFFFFHHHDHJJIIGIJJIJJJHFDDDDDDDBDDDDB############################################################\tNM:i:1\tMD:Z:2C38\tAS:i:38\tXS:i:38\n",
      "HS2000-690_130:4:2206:11079:24232\t0\t2\t299169\t4\t100M\t*\t0\t0\tATCCTAAGCAAAAAGAACAAAGCTGGAGGCATCATGTTACCTGACTTCAAACTATACTACAAGGCTACAGTAACCAAAACAGCATGGTACTGGTACCAAA\tCCCFFFDFGGHGGJJJJEGGIJIIIIEIJFBFGGGHEGGIGBHGGIGIJJIHIIJJJJJIIJJJJFEHGIHEEEH=?DFFDEA@ECBADDCCA>ACDDCA\tNM:i:2\tMD:Z:82T16T0\tAS:i:94\tXS:i:90\n",
      "samtools view: writing to standard output failed: Broken pipe\n",
      "samtools view: error closing standard output: -1\n"
     ]
    }
   ],
   "source": [
    "samtools view ./Results/S_Ju_hoan_North-3.bam | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a51e6-7c71-4ef9-b950-5101b55700a1",
   "metadata": {},
   "source": [
    "You can get useful statistics using `samtools flagstat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d340cd55-6262-4b17-b616-84c338c1db17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3845680 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "0 + 0 secondary\n",
      "1967 + 0 supplementary\n",
      "0 + 0 duplicates\n",
      "3809175 + 0 mapped (99.05% : N/A)\n",
      "31414 + 0 paired in sequencing\n",
      "15707 + 0 read1\n",
      "15707 + 0 read2\n",
      "3724 + 0 properly paired (11.85% : N/A)\n",
      "4014 + 0 with itself and mate mapped\n",
      "13699 + 0 singletons (43.61% : N/A)\n",
      "0 + 0 with mate mapped to a different chr\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "samtools flagstat ./Results/S_Ju_hoan_North-3.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ab924-800a-40c6-b352-e29393cd6faa",
   "metadata": {},
   "source": [
    "### Alignment with Minimap2\n",
    "\n",
    "[Minimap2](https://arxiv.org/abs/1708.01492) is a versatile sequence alignment program that aligns DNA or mRNA sequences against a large reference database. Typical use cases include: (1) mapping PacBio or Oxford Nanopore genomic reads to the human genome; (2) finding overlaps between long reads with error rate up to ~15%; (3) splice-aware alignment of PacBio Iso-Seq or Nanopore cDNA or Direct RNA reads against a reference genome; **(4) aligning Illumina single- or paired-end reads;** (5) assembly-to-assembly alignment; (6) full-genome alignment between two closely related species with divergence below ~15%. For >100bp Illumina short reads, minimap2 is three times as fast as BWA-MEM and Bowtie2, and as accurate on simulated data.\n",
    "\n",
    "We apply `minimap2` to the same data used for `bwa`. Here, the option `-x sr` is used to select a preset for a specific type of data. In our case, `sr` denotes *Short single-end reads without splicing*. More information about other alignment scenarios can be found [in the manual](https://lh3.github.io/minimap2/minimap2.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a90698-8eaa-46eb-9641-271fa7494a46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::mm_idx_gen::6.872*1.00] collected minimizers\n",
      "[M::mm_idx_gen::7.766*1.23] sorted minimizers\n",
      "[M::main::7.766*1.23] loaded/built the index for 1 target sequence(s)\n",
      "[M::mm_mapopt_update::7.766*1.23] mid_occ = 1000\n",
      "[M::mm_idx_stat] kmer size: 21; skip: 11; is_hpc: 0; #seq: 1\n",
      "[M::mm_idx_stat::8.201*1.21] distinct minimizers: 34516711 (96.91% are singletons); average occurrences: 1.154; average spacing: 6.108; total length: 243199373\n",
      "[M::worker_pipeline::20.089*2.30] mapped 500234 sequences\n",
      "[M::worker_pipeline::26.500*2.52] mapped 500191 sequences\n",
      "[M::worker_pipeline::33.960*2.66] mapped 500194 sequences\n",
      "[M::worker_pipeline::40.352*2.74] mapped 500202 sequences\n",
      "[M::worker_pipeline::45.576*2.80] mapped 500257 sequences\n",
      "[M::worker_pipeline::62.586*2.72] mapped 500275 sequences\n",
      "[M::worker_pipeline::64.095*2.67] mapped 500203 sequences\n",
      "[M::worker_pipeline::64.966*2.64] mapped 342157 sequences\n",
      "[M::main] Version: 2.24-r1122\n",
      "[M::main] CMD: minimap2 -a -x sr Reference/chr2.fa Data/fastq/S_Ju_hoan_North-3.region.fq\n",
      "[M::main] Real time: 65.094 sec; CPU: 171.885 sec; Peak RSS: 2.659 GB\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n"
     ]
    }
   ],
   "source": [
    "minimap2 -a -x sr Reference/chr2.fa Data/fastq/S_Ju_hoan_North-3.region.fq | \\\n",
    "                  samtools sort -O BAM -o './Results/S_Ju_hoan_North-3.minimap.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee2bc7-4974-418e-a193-18d537761c93",
   "metadata": {},
   "source": [
    "Look at the output on the screen from `bwa mem` and `minimap2`. Both the real time (the actual time you wait for the command to run) and the CPU time (how much time in total multiple CPUs have been working while you waited for the real time) should be lower for `minimap2`, since this is in general faster than `bwa mem`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97c291-e2c0-4d9e-aa97-8c69b41cbf73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore the results with the IGV software\n",
    "\n",
    "To visualize the alignment of the reads to the reference genome we have just produced, we will use the Integrative Genome Visualizer IGV. You can run it from your laptop after [downloading it](https://software.broadinstitute.org/software/igv/download), or running it through uCloud from the [Genomics Sandbox application](https://cloud.sdu.dk/app/jobs/create?app=genomics&version=2022.08.01) (only if you are an uCloud user). But first, we need to generate an index file for this software to work. Indexing a genome sorted BAM file allows one to quickly extract alignments overlapping particular genomic regions. Moreover, indexing is required by genome viewers such as IGV so that the viewers can quickly display alignments in each genomic region to which you navigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ba9aeb-da6c-490c-a264-ae5db718abfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools index ./Results/S_Ju_hoan_North-3.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3084cb-a258-4736-8e46-eaf46b7c85dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "IGV is an Integrative Genomics viewer and can be very useful to look at the results of Mapping and SNP calling. Three files are necessary to look at this dataset: the reference sequence and the\n",
    "`.bam` and `.bai` files in the `Results` folder. Since we are using a human reference, the sequence is already available in the software and does not need a download. Download the `.bam` and `.bai` files on your laptop, and if you want to use uCloud, upload them into one of your personal folders.\n",
    "\n",
    "### Reading in the data\n",
    "\n",
    "To select the reference genome, go to `Genomes ---> Load from server... ---> Filter by human` and choose the `Human hg19` reference.\n",
    "\n",
    "Now, you want to see the chromosomes and genes: download the mapping results by going to `File ---> Load from File... ----> S_Ju_hoan_North-3.bam`.\n",
    "\n",
    "When you zoom in to the lactase region on chromosome 2 (chr2:136,545,410-136,594,750), you will see something like this: ![](img/IGV_example.png)\n",
    "\n",
    "Try to understand what are the different attributes present in the viewer. If you zoom in very much you will find single nucleotide polymorphisms (SNPs), where the reference sequence does not have the same nucleotide as the data mapped to.\n",
    "\n",
    "## Analyzing read coverage\n",
    "\n",
    "One of the attributes one could learn from mapping reads back to the reference is the coverage of reads across the genome. In order to calculate the coverage depth you can use the command **samtools depth**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae81cf0-d478-49a5-8bcb-2ca0d90c6d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools depth Results/S_Ju_hoan_North-3.bam > Results/S_Ju_hoan_North-3.coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4abedb27-caa4-485d-b03d-55e5d5d8b371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t48688\t1\n",
      "2\t48689\t1\n",
      "2\t48690\t1\n",
      "2\t48691\t1\n",
      "2\t48692\t1\n",
      "2\t48693\t1\n",
      "2\t48694\t1\n",
      "2\t48695\t1\n",
      "2\t48696\t1\n",
      "2\t48697\t1\n"
     ]
    }
   ],
   "source": [
    "less Results/S_Ju_hoan_North-3.coverage | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c7243-0fe6-47b1-a2bd-183313d9710d",
   "metadata": {},
   "source": [
    "<img src=\"img/R.png\" alt=\"R\" width=\"80\"> We now switch to the `popgen course` kernel and use the `R` language to look at the depth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c12d422-fb24-4357-99f4-b1aea48a5592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.1.3”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.1.3”\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca4593c-c136-47f8-8863-af77dc5de4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 0 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Scaffold</th><th scope=col>locus</th><th scope=col>depth</th></tr>\n",
       "\t<tr><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 0 × 3\n",
       "\\begin{tabular}{lll}\n",
       " Scaffold & locus & depth\\\\\n",
       " <lgl> & <lgl> & <lgl>\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 0 × 3\n",
       "\n",
       "| Scaffold &lt;lgl&gt; | locus &lt;lgl&gt; | depth &lt;lgl&gt; |\n",
       "|---|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     Scaffold locus depth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaf <- read.table(\"./Results/S_Ju_hoan_North-3.coverage\", header=FALSE, sep=\"\\t\", \n",
    "                   na.strings=\"NA\", dec=\".\", strip.white=TRUE,\n",
    "                   col.names = c(\"Scaffold\", \"locus\", \"depth\"))\n",
    "    \n",
    "head(scaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6684f66-a62e-4f9c-b6be-571cf57abc31",
   "metadata": {},
   "source": [
    "We plot the average coverage in windows of 100 loci and save the plot in `Results/S_Ju_hoan_North-3.coverage.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbbb4a-a538-43bc-a1b4-8ac1846caf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average in windows\n",
    "scaf %>% \n",
    "mutate(rounded_position = round(locus, -2)) %>%\n",
    "    group_by(rounded_position) %>% \n",
    "        summarize(mean_cov = mean(depth)) -> compressed\n",
    "\n",
    "# Plotting the data\n",
    "p <- ggplot(data =  compressed, aes(x=rounded_position, y=mean_cov)) + geom_area() + theme_classic() + ylim(0, 400)\n",
    "\n",
    "# Saving your coverage plot\n",
    "ggsave(\"Results/S_Ju_hoan_North-3.coverage.pdf\",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d811bf7-6dec-43a7-97e2-3f4b0aa2dbf5",
   "metadata": {},
   "source": [
    "Look at the pdf with the plot of the coverage. What are the conclusions you can extract from these analysis? Does the coverage match with what you observed with IGV? Does it match with what you would expect, i.e what you know from the data? \n",
    "\n",
    "## SNP calling\n",
    "\n",
    "Even though just a tiny portion (around 2%) of our genomes are based of protein coding regions, this partition contains most of the disease causal variants (mutations), and that is why variant calling is so important from a medical point of view. From the population genetics side, it is also possible to use these variants to establish differences between individuals, populations and species. It can also be used to clarify the genetic basis of adaptation.\n",
    "\n",
    "Once we have mapped our reads we can now start with variant detection. We will use the [software `bcftools`](https://samtools.github.io/bcftools/howtos/index.html), a program for variant calling and manipulating files in the Variant Call Format (VCF) and its binary counterpart BCF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82139b35-0eed-45f3-b26b-ec55df3e63bb",
   "metadata": {},
   "source": [
    "You will be using the VCF format further in the course, for now let's just count the number of heterozygous SNPs in each individual:\n",
    "\n",
    "<img src=\"img/bash.png\" alt=\"Bash\" width=\"80\"> Choose the `Bash` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc718b1-0fe7-45cb-bd09-f0c058d39400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bcftools mpileup --threads 16 -Ou --skip-indels -f Reference/chr2.fa Results/S_Ju_hoan_North-3.bam | \\\n",
    "         bcftools call -mv -Ov -o Results/S_Ju_hoan_North-3.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44bc35-4d46-42f1-a704-03b9fa867059",
   "metadata": {},
   "source": [
    "The output is a single [VCF](http://samtools.github.io/hts-specs/VCFv4.2.pdf) file containing all the variants that `bcftools` identified.\n",
    "Look at the output vcf file. What does the format look like? Does that match with what you observed in the IGV? Download the VCF file to the IGV browser to look atthe SNPs.\n",
    "\n",
    "Here we can count how many line the file contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf1fa2-ab27-4d4f-b5a1-8d5ab7c0d668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "less ./Results/S_Ju_hoan_North-3.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ad39a-68d7-493b-b04d-2003ec37ff4f",
   "metadata": {},
   "source": [
    "Note that part of those lines (in this case 28) are just descriptions of the meaning of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9fef71-c67d-43bb-b0f6-02ead4adcfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "less ./Results/S_Ju_hoan_North-3.vcf | head -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290244ed-2a8e-4b2e-9c70-7fe1837040e0",
   "metadata": {},
   "source": [
    "The called genotype is written in the last column (together with other values) and can be\n",
    "\n",
    "-   0/0 - the sample is homozygous to the reference (note that these sites usually won't be listed in single sample vcf files as they are not variants)\n",
    "-   0/1 OR 0/1 - the sample is heterozygous, carrying 1 copy of each of the REF\n",
    "    and ALT alleles\n",
    "-   1/1 - the sample is homozygous for the alternate allele\n",
    "\n",
    "We can count how many of those different called genotype there are by using `grep`. For the homozigous alternate allele,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60601c5-fdd0-44bd-ae22-687c91b60435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grep '1/1' ./Results/S_Ju_hoan_North-3.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cb136f-6581-40df-bc7b-dc371c0698ff",
   "metadata": {},
   "source": [
    "For the homozigous genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51feaa4-b4aa-40d2-ac66-bd9c56e39a39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grep '0/1\\|1/0' ../../Results/S_Ju_hoan_North-3.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9cfb4-17e6-4e41-ac9d-6c20a87764b9",
   "metadata": {},
   "source": [
    "<img src=\"img/R.png\" alt=\"R\" width=\"80\"> Choose the `popgen course` kernel\n",
    "\n",
    "We can read in the vcf file in `R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d9573-1a62-4d03-b6f4-4542c56d7785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = read.table(\"../../Results/S_Ju_hoan_North-3.vcf\",header=FALSE, sep=\"\\t\", na.strings=\"NA\", dec=\".\", strip.white=TRUE)\n",
    "    \n",
    "head(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d4c14-3b8b-4526-adf3-288c2dde285c",
   "metadata": {},
   "source": [
    "Choose column number 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20867b64-5ce1-4711-96a9-1c21bae5e213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geno_column = t[['V10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7615c9e7-01de-407a-9d62-8ee4135396d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'1/1:33,3,0'</li><li>'1/1:32,3,0'</li><li>'1/1:47,6,0'</li><li>'1/1:32,3,0'</li><li>'1/1:48,9,0'</li><li>'1/1:54,9,0'</li><li>'1/1:48,3,0'</li><li>'1/1:53,9,0'</li><li>'1/1:30,1,0'</li><li>'1/1:33,3,0'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '1/1:33,3,0'\n",
       "\\item '1/1:32,3,0'\n",
       "\\item '1/1:47,6,0'\n",
       "\\item '1/1:32,3,0'\n",
       "\\item '1/1:48,9,0'\n",
       "\\item '1/1:54,9,0'\n",
       "\\item '1/1:48,3,0'\n",
       "\\item '1/1:53,9,0'\n",
       "\\item '1/1:30,1,0'\n",
       "\\item '1/1:33,3,0'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '1/1:33,3,0'\n",
       "2. '1/1:32,3,0'\n",
       "3. '1/1:47,6,0'\n",
       "4. '1/1:32,3,0'\n",
       "5. '1/1:48,9,0'\n",
       "6. '1/1:54,9,0'\n",
       "7. '1/1:48,3,0'\n",
       "8. '1/1:53,9,0'\n",
       "9. '1/1:30,1,0'\n",
       "10. '1/1:33,3,0'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"1/1:33,3,0\" \"1/1:32,3,0\" \"1/1:47,6,0\" \"1/1:32,3,0\" \"1/1:48,9,0\"\n",
       " [6] \"1/1:54,9,0\" \"1/1:48,3,0\" \"1/1:53,9,0\" \"1/1:30,1,0\" \"1/1:33,3,0\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geno_column[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c4689-c5ec-4fa8-9bdd-7de12a39be7d",
   "metadata": {},
   "source": [
    "For each element in the vector, choose only the part of text before `:`, so that the genotype is isolated from other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e0daa8-b40a-4462-b7e1-ec20d4c89165",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno = sapply(geno_column, function(x) unlist(strsplit(x,':'))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fd0cb85-5a2c-4a94-81da-8c6950ff5e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>1/1:33,3,0</dt><dd>'1/1'</dd><dt>1/1:32,3,0</dt><dd>'1/1'</dd><dt>1/1:47,6,0</dt><dd>'1/1'</dd><dt>1/1:32,3,0</dt><dd>'1/1'</dd><dt>1/1:48,9,0</dt><dd>'1/1'</dd><dt>1/1:54,9,0</dt><dd>'1/1'</dd><dt>1/1:48,3,0</dt><dd>'1/1'</dd><dt>1/1:53,9,0</dt><dd>'1/1'</dd><dt>1/1:30,1,0</dt><dd>'1/1'</dd><dt>1/1:33,3,0</dt><dd>'1/1'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1/1:33,3,0] '1/1'\n",
       "\\item[1/1:32,3,0] '1/1'\n",
       "\\item[1/1:47,6,0] '1/1'\n",
       "\\item[1/1:32,3,0] '1/1'\n",
       "\\item[1/1:48,9,0] '1/1'\n",
       "\\item[1/1:54,9,0] '1/1'\n",
       "\\item[1/1:48,3,0] '1/1'\n",
       "\\item[1/1:53,9,0] '1/1'\n",
       "\\item[1/1:30,1,0] '1/1'\n",
       "\\item[1/1:33,3,0] '1/1'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1/1:33,3,0\n",
       ":   '1/1'1/1:32,3,0\n",
       ":   '1/1'1/1:47,6,0\n",
       ":   '1/1'1/1:32,3,0\n",
       ":   '1/1'1/1:48,9,0\n",
       ":   '1/1'1/1:54,9,0\n",
       ":   '1/1'1/1:48,3,0\n",
       ":   '1/1'1/1:53,9,0\n",
       ":   '1/1'1/1:30,1,0\n",
       ":   '1/1'1/1:33,3,0\n",
       ":   '1/1'\n",
       "\n"
      ],
      "text/plain": [
       "1/1:33,3,0 1/1:32,3,0 1/1:47,6,0 1/1:32,3,0 1/1:48,9,0 1/1:54,9,0 1/1:48,3,0 \n",
       "     \"1/1\"      \"1/1\"      \"1/1\"      \"1/1\"      \"1/1\"      \"1/1\"      \"1/1\" \n",
       "1/1:53,9,0 1/1:30,1,0 1/1:33,3,0 \n",
       "     \"1/1\"      \"1/1\"      \"1/1\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geno[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aae514-0d4a-415f-9219-60ee8592efa2",
   "metadata": {},
   "source": [
    "Given this information you are now able to estimate the mean heterozygosity for your individual of the 10 MB region in chromosome 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ce92b0-3243-48d7-90d0-8c2bdc680d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.453159038729146"
      ],
      "text/latex": [
       "0.453159038729146"
      ],
      "text/markdown": [
       "0.453159038729146"
      ],
      "text/plain": [
       "[1] 0.453159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - (sum(geno=='0/1')/length(geno))^2 - (sum(geno=='1/1')/length(geno))^2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
