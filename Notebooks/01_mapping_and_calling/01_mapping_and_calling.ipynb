{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e39a7f3-7b5d-43db-ab17-6e1f1aa741a1",
   "metadata": {},
   "source": [
    "# Mapping and SNP Calling Tutorial\n",
    "\n",
    "High-throughput sequencing technologies have in the past few years been producing millions of reads of human genome and other species. To be useful, this genetic information has to be 'put together' in a smart way, in the same way as the pieces of a puzzle (reads) need to be mounted according to a picture (reference genome). \n",
    "\n",
    "The present tutorial, like the rest of the course material, is available at our [open-source github repository](https://github.com/hds-sandbox/Popgen_course_aarhus), and is based on [Kasper Munk's course repository](https://github.com/kaspermunch/PopulationGenomicsCourse).\n",
    "\n",
    "## Content\n",
    "\n",
    "In this exercise section you will be exposed to different softwares used for mapping reads to a reference sequence and calling variants from the produced alignments. We will use a dataset composed of 28 individuals from 3 different regions: Africa, EastAsia and WestEurasia. You can find the metadata file, containing sample IDs and some extra information for each sample here: `../../Data/metadata/Sample_meta_subset.tsv`\n",
    "\n",
    "![](img/unnamed-chunk-1-1.png)\n",
    "\n",
    "This dataset is a subset of the [Simons Diversity Project](https://www.nature.com/articles/nature18964).\n",
    "The following tutorial is based on the individual **S_Ju_hoan_North-3**, which is an african sample from Namibia.\n",
    "\n",
    "## How to make this notebook work\n",
    "\n",
    "* In this notebook we will use primarily `R` and `command line bash` commands.\n",
    "* This notebook integrates multiple coding languages. This means you need to choose a kernel every time we shift from one language to another. A kernel contains a programming language and the necessary packages to run the course material. To choose a kernel, go on the menu on the top of the page and select `Kernel --> Change Kernel`, and then select the preferred one. We will shift between two kernels, and along the code in this notebook you will see a picture telling you to change kernel. The two pictures are below:\n",
    "\n",
    "<img src=\"img/bash.png\" alt=\"Bash\" width=\"80\"> Shift to the `Bash` kernel\n",
    "\n",
    "<img src=\"img/R.png\" alt=\"R\" width=\"80\"> Shift to the `popgen course` kernel\n",
    "* You can run the code in each cell by clicking on the run cell sign in the toolbar, or simply by pressing <kbd>Shift</kbd>+<kbd>Enter</kbd>. When the code is done running, a small green check sign will appear on the left side.\n",
    "* You need to run the cells in sequential order to execute the analysis. Please do not run a cell until the one above is done running, and do not skip any cells\n",
    "* The code goes along with textual descriptions to help you understand what happens. Please try not to focus on understanding the code itself in too much detail - but rather try to focus on the explanations and on the output of the commands \n",
    "*   You can create new code cells by pressing `+` in the Menu bar above or by pressing <kbd>B</kbd> after you select a cell. \n",
    "\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "At the end of this tutorial you will be able to\n",
    "\n",
    "- **handle and understand** the various steps needed to prepare data for alignment using standard tools like `samtools`\n",
    "- **apply** genome alignment tools (`burrows-wheeler aligner BWA` and `Minimap2`) and **comment** their outcome\n",
    "- **make sense** of the various data formats (`fasta`, `fastq`, `sam/bam`, `vcf`, ...) \n",
    "- **explore and analyze** data on a genome viewer\n",
    "\n",
    "## Mapping reads against the reference\n",
    "\n",
    "The first step when dealing with raw reads is mapping (aligning) them to a reference sequence. We will use two different aligners for mapping the reads against the reference genome; one is the classical Burrows-Wheeler aligner (BWA), and the other is the newer and faster Minimap2. Minimap2 is especially faster (up to 50X faster) and as accurate as BWA in aligning long reads, but works also well with short read data like ours.\n",
    "\n",
    "Two input files are needed to do genome mapping:\n",
    "\n",
    "- Fasta file containing your reference genome Which was downloaded from [hg19](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/chromosomes/chr2.fa.gz). We need to copy the file from our `Data` folder, since it is a protected folder where we cannot write any file.\n",
    "- The reads in fastq format, which can be found in `Data/fastq/`. Here we will not need to copy the files to another folder, because we will only read them.\n",
    "\n",
    "We create a link to `Data`, so it is easier to access it. Then we make a folder called `Reference` and copy the file `chr2.fa` in it. Finally we create a folder where to save our results.\n",
    "\n",
    "<img src=\"img/bash.png\" alt=\"Bash\" width=\"80\"> Choose the `Bash` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68829ed0-a541-4eaa-b8d8-74d24dced0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mkdir -p ../../Reference\n",
    "cp ../../Data/fasta/chr2.fa ../../Reference/\n",
    "ln -s ../../Data\n",
    "ln -s ../../Reference\n",
    "mkdir -p Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be5f4e-f217-4bf9-b428-dc69dbd18363",
   "metadata": {},
   "source": [
    "### Alignment with BWA\n",
    "\n",
    "BWA allows for fast and accurate alignment of short reads to an indexed reference sequence. [Here](http://bio-bwa.sourceforge.net/bwa.shtml) is the manual. We will focus on a 10 MB region of chromosome 2 (from 135MB to 145MB), which contains the [lactase gene](https://www.genecards.org/cgi-bin/carddisp.pl?gene=LCT).\n",
    "\n",
    "First we need to index the reference file for later use. This creates index files used to perform the alignment. To produce these files, run the following command. Here, `-a bwtsw` specifies the indexing algorithm; specifically `bwtsw` which is capable of handling large genomes such as the human genome (the standard option is `-a is`, which cannot handle beyond 2MB genomes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9320e79-b360-4f78-9f17-925f32e747b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bwa index -a bwtsw Reference/chr2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7503e70-51c9-43d2-b63f-996fefa6a222",
   "metadata": {},
   "source": [
    "The resulting `bwa` index files are in the same folder `Reference` as the reference genome file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61775402-45a5-440c-a45c-34f695a4216e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb579a-6706-4eed-9b5a-13fcc4139f14",
   "metadata": {},
   "source": [
    "\n",
    "We also need to generate a fasta file index, which contains the genomic coordinates of the reference file. This can be done using the `samtools` program `faidx`. Again, the resulting index files are in the `Reference` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d39e37-4832-4a3a-9fa5-1b5be484e8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools faidx Reference/chr2.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e49451-2cc0-41b4-8754-6160f2f18aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86ff6a-921f-4baa-b66a-bb8b9a870cf2",
   "metadata": {},
   "source": [
    "Now you can map the reads to the reference. This will take a few minutes. Note how the alignment command `bwa mem` is piped with the symbol `|` at the end of the command. This allows the output of the alignment with `bwa mem` not to be written anywhere, but to be transferred (piped) directly into the following command `samtools sort`, which sorts the aligned genome by coordinates and creates a file in `bam` format. The sorting is necessary as the output of `bwa mem` is unsorted, and sorted files are usually the standard for genomic analysis. The piping speeds up the running time of the commands, avoiding to write intermediate files, and thus saving also disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f16461-5505-4562-af09-58df35d1dce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bwa mem -t 16 -p Reference/chr2.fa './Data/fastq/S_Ju_hoan_North-3.region.fq' | samtools sort -O BAM -o './Results/S_Ju_hoan_North-3.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07590a13-9da2-4498-b811-9960a49b00cc",
   "metadata": {},
   "source": [
    "Bam files follow this structure, where each element is tab-separated inside the output file:\n",
    "\n",
    "![Alt text](https://us.v-cdn.net/5019796/uploads/editor/f4/uuzmf2cbau1y.png)\n",
    "\n",
    "- Read name: ID for the given read.\n",
    "- Flags: Combination of bitwise FLAGs that provide information on how the read is mapped  [Extra information](https://broadinstitute.github.io/picard/explain-flags.html).\n",
    "- Position: Chromosome and position of the first base in the alignment. \n",
    "- MAPQ: Probability of wrong mapping of the read. It's in Phred scale, so higher numbers mean lower probabilities:\n",
    "![Alt_text](https://genome.sph.umich.edu/w/images/math/e/9/d/e9dc88d1834c4579de12153a67ac3afa.png)\n",
    "- CIGAR: summary of the alignment, including start position on the reference sequence, matches, mismatches, deletions and insertions. It may also include information on soft/hard clipping, i.e bases in the 3' and 5' ends of teh read that are not part of the alignment.\n",
    "[Extra information](https://wiki.bits.vib.be/index.php/CIGAR)\n",
    "- Mate information: chromosome and start position of teh read pair, and inferred insert size.\n",
    "- Quality scores: base qualities of the read.\n",
    "- Metadata: optional extra information. \n",
    "\n",
    "For more information, read [this](https://samtools.github.io/hts-specs/SAMv1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791666ad-5e7f-4c2a-b668-dd06d1f4b06e",
   "metadata": {},
   "source": [
    "Have a look at the bam file generated and compare it with the structure above. There is an error message, but do not mind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961004dc-2120-4965-8170-37429a90599a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools view ./Results/S_Ju_hoan_North-3.bam | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a51e6-7c71-4ef9-b950-5101b55700a1",
   "metadata": {},
   "source": [
    "You can get useful statistics using `samtools flagstat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340cd55-6262-4b17-b616-84c338c1db17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools flagstat ./Results/S_Ju_hoan_North-3.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ab924-800a-40c6-b352-e29393cd6faa",
   "metadata": {},
   "source": [
    "### Alignment with Minimap2\n",
    "\n",
    "[Minimap2](https://arxiv.org/abs/1708.01492) is a versatile sequence alignment program that aligns DNA or mRNA sequences against a large reference database. Typical use cases include: (1) mapping PacBio or Oxford Nanopore genomic reads to the human genome; (2) finding overlaps between long reads with error rate up to ~15%; (3) splice-aware alignment of PacBio Iso-Seq or Nanopore cDNA or Direct RNA reads against a reference genome; **(4) aligning Illumina single- or paired-end reads;** (5) assembly-to-assembly alignment; (6) full-genome alignment between two closely related species with divergence below ~15%. For >100bp Illumina short reads, minimap2 is three times as fast as BWA-MEM and Bowtie2, and as accurate on simulated data.\n",
    "\n",
    "We apply `minimap2` to the same data used for `bwa`. Here, the option `-x sr` is used to select a preset for a specific type of data. In our case, `sr` denotes *Short single-end reads without splicing*. More information about other alignment scenarios can be found [in the manual](https://lh3.github.io/minimap2/minimap2.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a90698-8eaa-46eb-9641-271fa7494a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimap2 -a -x sr Reference/chr2.fa Data/fastq/S_Ju_hoan_North-3.region.fq | \\\n",
    "                  samtools sort -O BAM -o './Results/S_Ju_hoan_North-3.minimap.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee2bc7-4974-418e-a193-18d537761c93",
   "metadata": {},
   "source": [
    "Look at the output on the screen from `bwa mem` and `minimap2`. Both the real time (the actual time you wait for the command to run) and the CPU time (how much time in total multiple CPUs have been working while you waited for the real time) should be lower for `minimap2`, since this is in general faster than `bwa mem`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97c291-e2c0-4d9e-aa97-8c69b41cbf73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore the results with the IGV software\n",
    "\n",
    "To visualize the alignment of the reads to the reference genome we have just produced, we will use the Integrative Genome Visualizer IGV. You can run it from your laptop after [downloading it](https://software.broadinstitute.org/software/igv/download), or running it through uCloud from the [Genomics Sandbox application](https://cloud.sdu.dk/app/jobs/create?app=genomics&version=2022.08.01) (only if you are an uCloud user). But first, we need to generate an index file for this software to work. Indexing a genome sorted BAM file allows one to quickly extract alignments overlapping particular genomic regions. Moreover, indexing is required by genome viewers such as IGV so that the viewers can quickly display alignments in each genomic region to which you navigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba9aeb-da6c-490c-a264-ae5db718abfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools index ./Results/S_Ju_hoan_North-3.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3084cb-a258-4736-8e46-eaf46b7c85dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "IGV is an Integrative Genomics viewer and can be very useful to look at the results of Mapping and SNP calling. Three files are necessary to look at this dataset: the reference sequence and the\n",
    "`.bam` and `.bai` files in the `Results` folder. Since we are using a human reference, the sequence is already available in the software and does not need a download. Download the `.bam` and `.bai` files on your laptop, and if you want to use uCloud, upload them into one of your personal folders.\n",
    "\n",
    "### Reading in the data\n",
    "\n",
    "To select the reference genome, go to `Genomes ---> Load from server... ---> Filter by human` and choose the `Human hg19` reference.\n",
    "\n",
    "Now, you want to see the chromosomes and genes: download the mapping results by going to `File ---> Load from File... ----> S_Ju_hoan_North-3.bam`.\n",
    "\n",
    "When you zoom in to the lactase region on chromosome 2 (chr2:136,545,410-136,594,750), you will see something like this: ![](img/IGV_example.png)\n",
    "\n",
    "Try to understand what are the different attributes present in the viewer. If you zoom in very much you will find single nucleotide polymorphisms (SNPs), where the reference sequence does not have the same nucleotide as the data mapped to.\n",
    "\n",
    "## Analyzing read coverage\n",
    "\n",
    "One of the attributes one could learn from mapping reads back to the reference is the coverage of reads across the genome. In order to calculate the coverage depth you can use the command **samtools depth**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae81cf0-d478-49a5-8bcb-2ca0d90c6d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samtools depth Results/S_Ju_hoan_North-3.bam > Results/S_Ju_hoan_North-3.coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abedb27-caa4-485d-b03d-55e5d5d8b371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "less Results/S_Ju_hoan_North-3.coverage | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c7243-0fe6-47b1-a2bd-183313d9710d",
   "metadata": {},
   "source": [
    "<img src=\"img/R.png\" alt=\"R\" width=\"80\"> We now switch to the `popgen course` kernel and use the `R` language to look at the depth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12d422-fb24-4357-99f4-b1aea48a5592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4593c-c136-47f8-8863-af77dc5de4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaf <- read.table(\"./Results/S_Ju_hoan_North-3.coverage\", header=FALSE, sep=\"\\t\", \n",
    "                   na.strings=\"NA\", dec=\".\", strip.white=TRUE,\n",
    "                   col.names = c(\"Scaffold\", \"locus\", \"depth\"))\n",
    "    \n",
    "head(scaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6684f66-a62e-4f9c-b6be-571cf57abc31",
   "metadata": {},
   "source": [
    "We plot the average coverage in windows of 100 loci and save the plot in `Results/S_Ju_hoan_North-3.coverage.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbbb4a-a538-43bc-a1b4-8ac1846caf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average in windows\n",
    "scaf %>% \n",
    "mutate(rounded_position = round(locus, -2)) %>%\n",
    "    group_by(rounded_position) %>% \n",
    "        summarize(mean_cov = mean(depth)) -> compressed\n",
    "\n",
    "# Plotting the data\n",
    "p <- ggplot(data =  compressed, aes(x=rounded_position, y=mean_cov)) + geom_area() + theme_classic() + ylim(0, 400)\n",
    "\n",
    "# Saving your coverage plot\n",
    "ggsave(\"Results/S_Ju_hoan_North-3.coverage.pdf\",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d811bf7-6dec-43a7-97e2-3f4b0aa2dbf5",
   "metadata": {},
   "source": [
    "Look at the pdf with the plot of the coverage. What are the conclusions you can extract from these analysis? Does the coverage match with what you observed with IGV? Does it match with what you would expect, i.e what you know from the data? \n",
    "\n",
    "## SNP calling\n",
    "\n",
    "Even though just a tiny portion (around 2%) of our genomes are based of protein coding regions, this partition contains most of the disease causal variants (mutations), and that is why variant calling is so important from a medical point of view. From the population genetics side, it is also possible to use these variants to establish differences between individuals, populations and species. It can also be used to clarify the genetic basis of adaptation.\n",
    "\n",
    "Once we have mapped our reads we can now start with variant detection. We will use the [software `bcftools`](https://samtools.github.io/bcftools/howtos/index.html), a program for variant calling and manipulating files in the Variant Call Format (VCF) and its binary counterpart BCF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82139b35-0eed-45f3-b26b-ec55df3e63bb",
   "metadata": {},
   "source": [
    "You will be using the VCF format further in the course, for now let's just count the number of heterozygous SNPs in each individual:\n",
    "\n",
    "<img src=\"img/bash.png\" alt=\"Bash\" width=\"80\"> Choose the `Bash` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc718b1-0fe7-45cb-bd09-f0c058d39400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bcftools mpileup --threads 16 -Ou --skip-indels -f Reference/chr2.fa Results/S_Ju_hoan_North-3.bam | \\\n",
    "         bcftools call -mv -Ov -o Results/S_Ju_hoan_North-3.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44bc35-4d46-42f1-a704-03b9fa867059",
   "metadata": {},
   "source": [
    "The output is a single [VCF](http://samtools.github.io/hts-specs/VCFv4.2.pdf) file containing all the variants that `bcftools` identified.\n",
    "Look at the output vcf file. What does the format look like? Does that match with what you observed in the IGV? Download the VCF file to the IGV browser to look atthe SNPs.\n",
    "\n",
    "Here we can count how many line the file contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf1fa2-ab27-4d4f-b5a1-8d5ab7c0d668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "less ./Results/S_Ju_hoan_North-3.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ad39a-68d7-493b-b04d-2003ec37ff4f",
   "metadata": {},
   "source": [
    "Note that part of those lines (in this case 28) are just descriptions of the meaning of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9fef71-c67d-43bb-b0f6-02ead4adcfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "less ./Results/S_Ju_hoan_North-3.vcf | head -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290244ed-2a8e-4b2e-9c70-7fe1837040e0",
   "metadata": {},
   "source": [
    "The called genotype is written in the last column (together with other values) and can be\n",
    "\n",
    "-   0/0 - the sample is homozygous to the reference (note that these sites usually won't be listed in single sample vcf files as they are not variants)\n",
    "-   0/1 OR 0/1 - the sample is heterozygous, carrying 1 copy of each of the REF\n",
    "    and ALT alleles\n",
    "-   1/1 - the sample is homozygous for the alternate allele\n",
    "\n",
    "We can count how many of those different called genotype there are by using `grep`. For the homozigous alternate allele,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60601c5-fdd0-44bd-ae22-687c91b60435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grep '1/1' ./Results/S_Ju_hoan_North-3.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cb136f-6581-40df-bc7b-dc371c0698ff",
   "metadata": {},
   "source": [
    "For the homozigous genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51feaa4-b4aa-40d2-ac66-bd9c56e39a39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grep '0/1\\|1/0' ../../Results/S_Ju_hoan_North-3.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9cfb4-17e6-4e41-ac9d-6c20a87764b9",
   "metadata": {},
   "source": [
    "<img src=\"img/R.png\" alt=\"R\" width=\"80\"> Choose the `popgen course` kernel\n",
    "\n",
    "We can read in the vcf file in `R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d9573-1a62-4d03-b6f4-4542c56d7785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = read.table(\"../../Results/S_Ju_hoan_North-3.vcf\",header=FALSE, sep=\"\\t\", na.strings=\"NA\", dec=\".\", strip.white=TRUE)\n",
    "    \n",
    "head(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d4c14-3b8b-4526-adf3-288c2dde285c",
   "metadata": {},
   "source": [
    "Choose column number 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20867b64-5ce1-4711-96a9-1c21bae5e213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geno_column = t[['V10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615c9e7-01de-407a-9d62-8ee4135396d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geno_column[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c4689-c5ec-4fa8-9bdd-7de12a39be7d",
   "metadata": {},
   "source": [
    "For each element in the vector, choose only the part of text before `:`, so that the genotype is isolated from other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0daa8-b40a-4462-b7e1-ec20d4c89165",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno = sapply(geno_column, function(x) unlist(strsplit(x,':'))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0cb85-5a2c-4a94-81da-8c6950ff5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aae514-0d4a-415f-9219-60ee8592efa2",
   "metadata": {},
   "source": [
    "Given this information you are now able to estimate the mean heterozygosity for your individual of the 10 MB region in chromosome 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce92b0-3243-48d7-90d0-8c2bdc680d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (sum(geno=='0/1')/length(geno))^2 - (sum(geno=='1/1')/length(geno))^2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
